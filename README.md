# LangAgent: Agente con LangGraph, LLaMA3 y Chroma Vector Store

<div align="center">
  <!-- Nota: Puedes aÃ±adir un logo personalizado en esta ubicaciÃ³n -->
  <br>
  <em>Un sistema RAG con enrutamiento inteligente y mecanismos de reintento</em>
</div>

## ğŸŒŸ DescripciÃ³n

LangAgent es un sistema de respuesta a preguntas (Question Answering) que implementa un agente local utilizando LangGraph, LLaMA3 y Chroma Vector Store. El sistema organiza el conocimiento en "cubos" temÃ¡ticos dentro de diferentes "Ã¡mbitos", permitiendo un enrutamiento inteligente de preguntas y mecanismos de reintento para garantizar respuestas de alta calidad.

## ğŸ” CaracterÃ­sticas Principales

- **OrganizaciÃ³n JerÃ¡rquica del Conocimiento**: Estructura de "cubos" y "Ã¡mbitos" para organizar documentos
- **RAG Adaptativo**: Enrutamiento inteligente de preguntas al vector store basado en el contenido
- **RAG Correctivo**: Mecanismo de reintento (hasta 3 intentos) cuando las respuestas no son satisfactorias
- **EvaluaciÃ³n MÃºltiple**: EvalÃºa tanto la relevancia de los documentos como la calidad de las respuestas
- **AutenticaciÃ³n Segura**: Sistema de autenticaciÃ³n basado en tokens JWT para la API
- **Optimizado para Terminal**: Adaptado para entornos sin interfaz grÃ¡fica

## ğŸ”„ Workflow del Sistema

El sistema implementa un flujo de trabajo sofisticado basado en LangGraph:

<!-- Puedes incluir aquÃ­ el diagrama del workflow generado -->

El workflow consta de tres nodos principales:
1. **Route Question**: Determina quÃ© cubos son relevantes para la pregunta
2. **Retrieve**: Recupera documentos relevantes de los cubos seleccionados
3. **Generate**: Genera una respuesta basada en los documentos recuperados

## ğŸ“ Estructura del Proyecto

```
langagent/
â”œâ”€â”€ api/                  # MÃ³dulos para la API FastAPI
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ fastapi_app.py    # ImplementaciÃ³n de la API
â”œâ”€â”€ auth/                 # MÃ³dulos para autenticaciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ authentication.py # Funciones de autenticaciÃ³n JWT
â”œâ”€â”€ config/               # Configuraciones
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py         # Configuraciones del sistema
â”œâ”€â”€ data/                 # Directorio para datos
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ models/               # Modelos y flujo de trabajo
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ constants.py      # Constantes del sistema
â”‚   â”œâ”€â”€ llm.py            # ConfiguraciÃ³n de modelos de lenguaje
â”‚   â””â”€â”€ workflow.py       # ImplementaciÃ³n del flujo con LangGraph
â”œâ”€â”€ utils/                # Utilidades
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ document_loader.py       # Carga de documentos markdown
â”‚   â”œâ”€â”€ terminal_visualization.py # VisualizaciÃ³n en terminal
â”‚   â””â”€â”€ vectorstore.py           # ConfiguraciÃ³n de vectorstore
â”œâ”€â”€ __init__.py
â”œâ”€â”€ main.py               # Script principal
â””â”€â”€ requirements.txt      # Dependencias del proyecto
```

## ğŸ› ï¸ Componentes TÃ©cnicos

- **Modelos LLM**: Utiliza modelos de Ollama (LLaMA3) para diferentes tareas
- **Embeddings**: HuggingFace Embeddings (multilingual-e5-large-instruct)
- **Vector Store**: Chroma DB para almacenamiento y recuperaciÃ³n eficiente
- **Framework de Flujo**: LangGraph para orquestar el flujo de trabajo
- **API**: FastAPI para exponer la funcionalidad como servicio web

## ğŸ“‹ Requisitos

Las principales dependencias son:

- Python 3.10+
- langchain y langgraph
- chromadb
- huggingface_hub
- unstructured[md]
- fastapi y uvicorn
- authlib
- ollama (instalado localmente)

Ver el archivo `requirements.txt` para la lista completa de dependencias.

## ğŸš€ InstalaciÃ³n

1. Clona el repositorio:
   ```bash
   git clone https://github.com/carloss4dv/langagent.git
   cd langagent
   ```

2. Crea un entorno virtual:
   ```bash
   python -m venv venv
   source venv/bin/activate  # En Windows: venv\Scripts\activate
   ```

3. Instala las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

4. AsegÃºrate de tener Ollama instalado con los modelos LLaMA3 disponibles localmente:
   ```bash
   ollama pull llama3
   ```

## ğŸ’» Uso

### Modo Interactivo

Para iniciar el agente en modo interactivo:

```bash
python -m langagent.main --data_dir ./data --chroma_dir ./chroma --local_llm llama3
```

### Responder a una Pregunta EspecÃ­fica

Para responder a una pregunta especÃ­fica:

```bash
python -m langagent.main --data_dir ./data --chroma_dir ./chroma --local_llm llama3 --question "Â¿QuÃ© son los alumnos matriculados?"
```

### Iniciar la API

Para iniciar la API FastAPI:

```bash
uvicorn langagent.api.fastapi_app:app --host 0.0.0.0 --port 5001
```

## ğŸ”„ Mecanismo de Reintento y EvaluaciÃ³n

El sistema implementa un sofisticado mecanismo de evaluaciÃ³n y reintento:

1. **EvaluaciÃ³n de Documentos**: Determina si los documentos recuperados son relevantes para la pregunta
2. **EvaluaciÃ³n de Alucinaciones**: Verifica si la respuesta generada contiene informaciÃ³n no respaldada por los documentos
3. **EvaluaciÃ³n de Respuesta**: Comprueba si la respuesta aborda adecuadamente la pregunta original
4. **Reintento Adaptativo**: Si alguna evaluaciÃ³n falla, el sistema reintenta con ajustes (hasta 3 veces)
5. **Estrategia de Ãšltimo Recurso**: En el Ãºltimo intento, utiliza todos los cubos disponibles

## ğŸ§  OrganizaciÃ³n del Conocimiento

El sistema organiza los documentos en:

- **Ãmbitos**: CategorÃ­as amplias de conocimiento (ej. acadÃ©mico, admisiÃ³n, docencia)
- **Cubos**: Subconjuntos temÃ¡ticos dentro de cada Ã¡mbito

Esta estructura jerÃ¡rquica permite un enrutamiento mÃ¡s preciso de las preguntas y una recuperaciÃ³n mÃ¡s eficiente de la informaciÃ³n relevante.

## ğŸ“Š VisualizaciÃ³n en Terminal

Todas las visualizaciones han sido adaptadas para entornos de terminal, utilizando formato de texto en lugar de grÃ¡ficos. El mÃ³dulo `terminal_visualization.py` proporciona funciones para mostrar:

- Progreso del procesamiento
- Documentos recuperados con puntuaciones de relevancia
- Evaluaciones de calidad de respuesta
- EstadÃ­sticas de rendimiento

## ğŸ”’ Seguridad

El sistema implementa autenticaciÃ³n JWT para la API, permitiendo:

- GeneraciÃ³n segura de tokens
- VerificaciÃ³n de autenticidad
- Control de acceso a endpoints
- ExpiraciÃ³n configurable de tokens


## ğŸ“ Notas Importantes

- El sistema estÃ¡ configurado para trabajar con archivos markdown (.md)
- La base de datos vectorial (Chroma) se guarda en el directorio especificado para su reutilizaciÃ³n
- Para un rendimiento Ã³ptimo, se recomienda usar GPU para los modelos de embeddings


<div align="center">
  <p>Desarrollado con â¤ï¸ por el equipo de LangAgent</p>
</div>
